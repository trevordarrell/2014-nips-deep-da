\begin{table*}
\centering
\begin{tabular}{lccc}
\toprule
Adaptation Method & Training Data & DeCAF$_6$ & DeCAF$_7$ \\
\midrule
SVM (source only) & Amazon & $50.28 \pm 1.8$ & \textcolor{blue}{$\bm{54.08 \pm 1.7}$} \\
SVM (target only) & Webcam & $62.28 \pm 1.8$ & $64.97 \pm 1.8$ \\
\midrule
GFK \cite{gong-cvpr12} & Amazon & \textcolor{blue}{$\bm{53.13 \pm 1.1}$} & \textcolor{blue}{$\bm{53.39 \pm 1.1}$} \\
SA \cite{sa} & Amazon & $51.74 \pm 1.2$ & \textcolor{blue}{$\bm{53.86 \pm 1.0}$ }\\
\bottomrule
\end{tabular}

\caption{Amazon$\rightarrow$Webcam adaptation experiment. We show here
  multiclass accuracy on the target domain test set for both supervised and
  unsupervised adaptation experiments across the two fully connected layer
  features (similar to \cite{deeplearning-arxiv-2013}, but with one labeled
  target example). The best performing unsupervised adaptation algorithms are
  shown in blue and the best performing supervised adaptation algorithms are
  shown in red.}


\label{tab:fc6and7_amazon_unsup}
\end{table*}
