% conclusion
In this paper, we presented the first evaluation of domain adaptation from a
large-scale source dataset with deep features. We demonstrated that, although
using ImageNet as a source domain generalizes better than other smaller source
domains, there is still a domain shift when adapting to other visual domains.
\ks{ here I would repeat the lesson from above, that large scale helps unless domains are close}

We also proposed a simple yet novel deep domain adaptation framework, as well as
three particular methods DFE, DLF, and DSA, inspired by classic domain
adaptation methods~\cite{daume, sa}. Our methods incorporate A-distance to
non-parametrically select a layer that will provide strong adaptation
performance. We showed that our methods outperform the standard method of
adapting a convolutional network via fine tuning in the setting where a limited
number of labeled target examples are available. We also demonstrated that our
methods achieve state-of-the-art performance on the standard visual domain
adaptation benchmark.

In the future we would like to use our framework in combination with category invariant adaptation methods. This would enable us to evaluate performance in the realistic scenario of having labeled target examples for a subset of the categories we want to classify. 
